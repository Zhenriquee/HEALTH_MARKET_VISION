{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Oa7cHiEpspIkovnW_1S2e5TRd3w7Mj7q",
      "authorship_tag": "ABX9TyPgLt3r2+0qQyBTXaWozBBA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhenriquee/ANALISE_OPERADORAS/blob/main/Extra%C3%A7%C3%A3o_e_Tratamento_dos_Dados_ANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta e Tratamento de Dados da ANS"
      ],
      "metadata": {
        "id": "6cxjhRlYP6JT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo:\n",
        "Realizar a extração dos dados da ANS com a finalidade de analisar o posicionamento da Unimed Caruaru com Relação as outras Operadoras, no final iremos armazenar esses dados em um arquivo .db e Utilizar o streamlit para projeção desses dados."
      ],
      "metadata": {
        "id": "rCC815l2RBWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Links Utilizados para Extração\n",
        "\n",
        "\n",
        "*   [Qtd. Beneficiarios por Trimestre](https://dadosabertos.ans.gov.br/FTP/Base_de_dados/Microdados/dados_dbc/beneficiarios/operadoras/)\n",
        "*   [Demonstração Contabeis](https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/)\n",
        "\n"
      ],
      "metadata": {
        "id": "RvLj1QOxP6Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliotecas Utilizadas"
      ],
      "metadata": {
        "id": "83gT3xLJYs1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import re\n",
        "import io\n",
        "import zipfile\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from datasus_dbc import decompress\n",
        "from dbfread import DBF\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed"
      ],
      "metadata": {
        "id": "1qo5p9oOYwF2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicio Extração e Tratamento Qtd. Beneficiarios por Trimestre\n",
        "\n"
      ],
      "metadata": {
        "id": "GD1UCLoJP6EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FUNÇÕES AUXILIARES (Worker) ---\n",
        "# Precisam estar fora da classe para o multiprocessing funcionar bem no Windows\n",
        "\n",
        "def _gerar_chave_trimestre(id_cmpt):\n",
        "    try:\n",
        "        s_cmpt = str(id_cmpt).strip()\n",
        "        if len(s_cmpt) < 6: return None\n",
        "        ano = s_cmpt[:4]\n",
        "        mes = int(s_cmpt[4:6])\n",
        "        trimestre = (mes - 1) // 3 + 1\n",
        "        return f\"{ano}-T{trimestre}\"\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def processar_arquivo_worker(link):\n",
        "    \"\"\"\n",
        "    Função isolada que roda em um núcleo separado da CPU.\n",
        "    Baixa, Converte, Filtra e Agrupa. Retorna um DataFrame pronto (ou None).\n",
        "    \"\"\"\n",
        "    nome_arquivo = link.split('/')[-1]\n",
        "\n",
        "    # Gera nomes únicos para evitar colisão entre processos\n",
        "    id_unico = str(uuid.uuid4())\n",
        "    temp_dbc = f\"temp_{id_unico}.dbc\"\n",
        "    temp_dbf = f\"temp_{id_unico}.dbf\"\n",
        "\n",
        "    colunas_desejadas = ['ID_CMPT', 'CD_OPERADO', 'NR_BENEF_T']\n",
        "    resultado_df = None\n",
        "\n",
        "    try:\n",
        "        # 1. Download\n",
        "        r = requests.get(link, stream=True, timeout=30)\n",
        "        with open(temp_dbc, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        # 2. Descompressão\n",
        "        decompress(temp_dbc, temp_dbf)\n",
        "\n",
        "        # 3. Leitura e Pandas\n",
        "        table = DBF(temp_dbf, encoding='iso-8859-1', load=True)\n",
        "        df = pd.DataFrame(iter(table))\n",
        "\n",
        "        if not df.empty:\n",
        "            # Verifica colunas\n",
        "            if all(col in df.columns for col in colunas_desejadas):\n",
        "                df = df[colunas_desejadas].copy()\n",
        "                df['NR_BENEF_T'] = pd.to_numeric(df['NR_BENEF_T'], errors='coerce').fillna(0)\n",
        "\n",
        "                # Agrupa e Soma (Reduzindo drasticamente o tamanho dos dados antes de retornar)\n",
        "                df_agrupado = df.groupby(['ID_CMPT', 'CD_OPERADO'], as_index=False)['NR_BENEF_T'].sum()\n",
        "\n",
        "                # Cria chave Trimestre\n",
        "                df_agrupado['ID_TRIMESTRE'] = df_agrupado['ID_CMPT'].apply(_gerar_chave_trimestre)\n",
        "\n",
        "                resultado_df = df_agrupado\n",
        "            else:\n",
        "                print(f\"   [Worker] Ignorado {nome_arquivo}: Colunas ausentes.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   [Worker] Erro em {nome_arquivo}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Limpeza rigorosa dos arquivos temporários deste processo\n",
        "        if os.path.exists(temp_dbc): os.remove(temp_dbc)\n",
        "        if os.path.exists(temp_dbf): os.remove(temp_dbf)\n",
        "\n",
        "    return resultado_df\n",
        "\n",
        "# --- CLASSE PRINCIPAL ---\n",
        "\n",
        "class ImportadorANSParalelo:\n",
        "    def __init__(self, db_path='dados_ans.db'):\n",
        "        self.db_path = db_path\n",
        "\n",
        "    def etapa_1_e_2_obter_links(self, url_origem):\n",
        "        print(f\"--- Mapeando arquivos em: {url_origem} ---\")\n",
        "        try:\n",
        "            response = requests.get(url_origem)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            links = []\n",
        "            for link in soup.find_all('a'):\n",
        "                href = link.get('href')\n",
        "                if href and href.lower().endswith('.dbc'):\n",
        "                    links.append(urljoin(url_origem, href))\n",
        "            print(f\"Total de arquivos encontrados: {len(links)}\")\n",
        "            return links\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao obter links: {e}\")\n",
        "            return []\n",
        "\n",
        "    def etapa_3_processar_paralelo(self, lista_links, tabela_destino='beneficiarios_agrupados', max_workers=4):\n",
        "        \"\"\"\n",
        "        Gerencia os workers e grava no banco sequencialmente.\n",
        "        \"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        total = len(lista_links)\n",
        "        processados = 0\n",
        "\n",
        "        print(f\"--- Iniciando Processamento Paralelo ({max_workers} Workers) ---\")\n",
        "\n",
        "        # Inicia o Pool de Processos\n",
        "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "            # Submete todas as tarefas\n",
        "            # future_to_link é um dicionário para rastrear qual link pertence a qual tarefa\n",
        "            future_to_link = {executor.submit(processar_arquivo_worker, link): link for link in lista_links}\n",
        "\n",
        "            for future in as_completed(future_to_link):\n",
        "                processados += 1\n",
        "                link = future_to_link[future]\n",
        "                nome = link.split('/')[-1]\n",
        "\n",
        "                try:\n",
        "                    df_resultado = future.result()\n",
        "\n",
        "                    if df_resultado is not None and not df_resultado.empty:\n",
        "                        # O momento da escrita no banco é sequencial (Thread Principal)\n",
        "                        df_resultado.to_sql(tabela_destino, conn, if_exists='append', index=False)\n",
        "                        print(f\"[{processados}/{total}] Salvo: {nome} ({len(df_resultado)} registros)\")\n",
        "                    else:\n",
        "                        print(f\"[{processados}/{total}] Vazio/Ignorado: {nome}\")\n",
        "\n",
        "                except Exception as exc:\n",
        "                    print(f\"[{processados}/{total}] Falha ao recuperar resultado de {nome}: {exc}\")\n",
        "\n",
        "        conn.close()\n",
        "        print(\"--- Processo Paralelo Finalizado ---\")\n",
        "\n",
        "# --- EXECUÇÃO ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # URL da ANS\n",
        "    url_ans = \"https://dadosabertos.ans.gov.br/FTP/Base_de_dados/Microdados/dados_dbc/beneficiarios/operadoras/\"\n",
        "\n",
        "    # Define quantos núcleos do processador você quer usar\n",
        "    # Se seu PC for potente, pode aumentar. Geralmente 4 ou 8 é um bom número.\n",
        "    WORKERS = os.cpu_count() or 4\n",
        "\n",
        "    bot = ImportadorANSParalelo(db_path='base_ans_paralela.db')\n",
        "\n",
        "    links = bot.etapa_1_e_2_obter_links(url_ans)\n",
        "\n",
        "    if links:\n",
        "        # Executa em paralelo\n",
        "        bot.etapa_3_processar_paralelo(links, max_workers=WORKERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-hknZKxLRcmx",
        "outputId": "a376dcd5-662b-4122-b762-bf4280e75303"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Mapeando arquivos em: https://dadosabertos.ans.gov.br/FTP/Base_de_dados/Microdados/dados_dbc/beneficiarios/operadoras/ ---\n",
            "Total de arquivos encontrados: 58\n",
            "--- Iniciando Processamento Paralelo (2 Workers) ---\n",
            "[1/58] Salvo: tb_cc_2011-09.dbc (1405 registros)\n",
            "[2/58] Salvo: tb_cc_2011-06.dbc (1413 registros)\n",
            "[3/58] Salvo: tb_cc_2011-12.dbc (1391 registros)\n",
            "[4/58] Salvo: tb_cc_2012-03.dbc (1384 registros)\n",
            "[5/58] Salvo: tb_cc_2012-06.dbc (1377 registros)\n",
            "[6/58] Salvo: tb_cc_2012-09.dbc (1356 registros)\n",
            "[7/58] Salvo: tb_cc_2012-12.dbc (1346 registros)\n",
            "[8/58] Salvo: tb_cc_2013-03.dbc (1330 registros)\n",
            "[9/58] Salvo: tb_cc_2013-06.dbc (1307 registros)\n",
            "[10/58] Salvo: tb_cc_2013-09.dbc (1295 registros)\n",
            "[11/58] Salvo: tb_cc_2013-12.dbc (1276 registros)\n",
            "[12/58] Salvo: tb_cc_2014-03.dbc (1271 registros)\n",
            "[13/58] Salvo: tb_cc_2014-06.dbc (1260 registros)\n",
            "[14/58] Salvo: tb_cc_2014-09.dbc (1242 registros)\n",
            "[15/58] Salvo: tb_cc_2014-12.dbc (1243 registros)\n",
            "[16/58] Salvo: tb_cc_2015-03.dbc (1221 registros)\n",
            "[17/58] Salvo: tb_cc_2015-06.dbc (1210 registros)\n",
            "[18/58] Salvo: tb_cc_2015-09.dbc (1185 registros)\n",
            "[19/58] Salvo: tb_cc_2015-12.dbc (1162 registros)\n",
            "[20/58] Salvo: tb_cc_2016-03.dbc (1143 registros)\n",
            "[21/58] Salvo: tb_cc_2016-06.dbc (1122 registros)\n",
            "[22/58] Salvo: tb_cc_2016-09.dbc (1112 registros)\n",
            "[23/58] Salvo: tb_cc_2016-12.dbc (1105 registros)\n",
            "[24/58] Salvo: tb_cc_2017-03.dbc (1090 registros)\n",
            "[25/58] Salvo: tb_cc_2017-06.dbc (1082 registros)\n",
            "[26/58] Salvo: tb_cc_2017-09.dbc (1074 registros)\n",
            "[27/58] Salvo: tb_cc_2017-12.dbc (1061 registros)\n",
            "[28/58] Salvo: tb_cc_2018-03.dbc (1060 registros)\n",
            "[29/58] Salvo: tb_cc_2018-06.dbc (1055 registros)\n",
            "[30/58] Salvo: tb_cc_2018-09.dbc (1055 registros)\n",
            "[31/58] Salvo: tb_cc_2018-12.dbc (1039 registros)\n",
            "[32/58] Salvo: tb_cc_2019-03.dbc (1026 registros)\n",
            "[33/58] Salvo: tb_cc_2019-06.dbc (1021 registros)\n",
            "[34/58] Salvo: tb_cc_2019-09.dbc (1014 registros)\n",
            "[35/58] Salvo: tb_cc_2019-12.dbc (1014 registros)\n",
            "[36/58] Salvo: tb_cc_2020-03.dbc (1010 registros)\n",
            "[37/58] Salvo: tb_cc_2020-06.dbc (992 registros)\n",
            "[38/58] Salvo: tb_cc_2020-09.dbc (984 registros)\n",
            "[39/58] Salvo: tb_cc_2020-12.dbc (972 registros)\n",
            "[40/58] Salvo: tb_cc_2021-03.dbc (966 registros)\n",
            "[41/58] Salvo: tb_cc_2021-06.dbc (965 registros)\n",
            "[42/58] Salvo: tb_cc_2021-09.dbc (961 registros)\n",
            "[43/58] Salvo: tb_cc_2021-12.dbc (949 registros)\n",
            "[44/58] Salvo: tb_cc_2022-03.dbc (949 registros)\n",
            "[45/58] Salvo: tb_cc_2022-06.dbc (943 registros)\n",
            "[46/58] Salvo: tb_cc_2022-09.dbc (936 registros)\n",
            "[47/58] Salvo: tb_cc_2022-12.dbc (925 registros)\n",
            "[48/58] Salvo: tb_cc_2023-03.dbc (921 registros)\n",
            "[49/58] Salvo: tb_cc_2023-06.dbc (917 registros)\n",
            "[50/58] Salvo: tb_cc_2023-09.dbc (917 registros)\n",
            "[51/58] Salvo: tb_cc_2023-12.dbc (917 registros)\n",
            "[52/58] Salvo: tb_cc_2024-03.dbc (917 registros)\n",
            "[53/58] Salvo: tb_cc_2024-06.dbc (908 registros)\n",
            "[54/58] Salvo: tb_cc_2024-09.dbc (909 registros)\n",
            "[55/58] Salvo: tb_cc_2024-12.dbc (908 registros)\n",
            "[56/58] Salvo: tb_cc_2025-03.dbc (904 registros)\n",
            "[57/58] Salvo: tb_cc_2025-06.dbc (899 registros)\n",
            "[58/58] Salvo: tb_cc_2025-09.dbc (894 registros)\n",
            "--- Processo Paralelo Finalizado ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicio Extração e Tratamento Demonstração Contabeis"
      ],
      "metadata": {
        "id": "6OGHjnffP557"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtratorContabil:\n",
        "    def __init__(self, db_path='dados_ans.db'):\n",
        "        self.db_path = db_path\n",
        "        self.url_base = \"https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/\"\n",
        "\n",
        "    def _obter_links_anos(self):\n",
        "        \"\"\"Busca as pastas de anos (ex: 2022/, 2023/)\"\"\"\n",
        "        print(f\"--- Buscando pastas de anos em: {self.url_base} ---\")\n",
        "        try:\n",
        "            response = requests.get(self.url_base)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            links_anos = []\n",
        "            for link in soup.find_all('a'):\n",
        "                href = link.get('href')\n",
        "                # Procura por pastas que pareçam anos (4 digitos + /)\n",
        "                if href and re.match(r'\\d{4}/', href):\n",
        "                    full_link = urljoin(self.url_base, href)\n",
        "                    links_anos.append(full_link)\n",
        "\n",
        "            return links_anos\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao listar anos: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _obter_zips_do_ano(self, url_ano):\n",
        "        \"\"\"Dentro da pasta do ano, busca os arquivos .zip\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url_ano)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            links_zips = []\n",
        "            for link in soup.find_all('a'):\n",
        "                href = link.get('href')\n",
        "                if href and href.lower().endswith('.zip'):\n",
        "                    full_link = urljoin(url_ano, href)\n",
        "                    links_zips.append(full_link)\n",
        "            return links_zips\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao listar zips de {url_ano}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _extrair_trimestre_do_nome(self, nome_arquivo):\n",
        "        \"\"\"\n",
        "        Analisa o nome '1T2024.zip' ou '2024_1T.zip' e retorna '2024-T1'\n",
        "        \"\"\"\n",
        "        # Regex para capturar Trimestre (1 a 4) e Ano (20xx)\n",
        "        # Padrão comum na ANS: 1T2022, 1t2022, etc.\n",
        "        match = re.search(r'([1-4])t(20\\d{2})', nome_arquivo.lower())\n",
        "\n",
        "        if match:\n",
        "            trimestre = match.group(1)\n",
        "            ano = match.group(2)\n",
        "            return f\"{ano}-T{trimestre}\"\n",
        "\n",
        "        # Tentativa de padrão inverso (caso exista 2022_1t)\n",
        "        match_inv = re.search(r'(20\\d{2}).*([1-4])t', nome_arquivo.lower())\n",
        "        if match_inv:\n",
        "            ano = match_inv.group(1)\n",
        "            trimestre = match_inv.group(2)\n",
        "            return f\"{ano}-T{trimestre}\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def executar_extracao(self, tabela_destino='demonstracoes_contabeis'):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "\n",
        "        pastas_anos = self._obter_links_anos()\n",
        "\n",
        "        for pasta in pastas_anos:\n",
        "            print(f\"> Entrando na pasta: {pasta}\")\n",
        "            links_zips = self._obter_zips_do_ano(pasta)\n",
        "\n",
        "            for link_zip in links_zips:\n",
        "                nome_arquivo = link_zip.split('/')[-1]\n",
        "                chave_trimestre = self._extrair_trimestre_do_nome(nome_arquivo)\n",
        "\n",
        "                if not chave_trimestre:\n",
        "                    print(f\"   [Pular] Não foi possível identificar trimestre no nome: {nome_arquivo}\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"   Processing: {nome_arquivo} -> Trimestre: {chave_trimestre}\")\n",
        "\n",
        "                try:\n",
        "                    # 1. Download em Memória (Stream)\n",
        "                    r = requests.get(link_zip)\n",
        "\n",
        "                    # 2. Abrir ZIP da memória (io.BytesIO)\n",
        "                    with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
        "                        # Procura o CSV dentro do zip\n",
        "                        csvs = [n for n in z.namelist() if n.lower().endswith('.csv')]\n",
        "\n",
        "                        if not csvs:\n",
        "                            print(\"   [Erro] Nenhum CSV encontrado dentro do zip.\")\n",
        "                            continue\n",
        "\n",
        "                        # Vamos assumir que o primeiro CSV é o correto\n",
        "                        nome_csv = csvs[0]\n",
        "\n",
        "                        # 3. Ler CSV direto do ZIP\n",
        "                        with z.open(nome_csv) as f:\n",
        "                            # ANS costuma usar separador ';' e encoding 'latin1' ou 'utf-8'\n",
        "                            # 'CD_CONTA_CONTABIL' as vezes vem como string ou int, vamos forçar conversão depois\n",
        "                            df = pd.read_csv(f, sep=';', encoding='iso-8859-1', dtype=str)\n",
        "\n",
        "                            # Tratamento de colunas (Minúsculo para padronizar busca)\n",
        "                            df.columns = [c.upper() for c in df.columns]\n",
        "\n",
        "                            if 'CD_CONTA_CONTABIL' in df.columns:\n",
        "                                # 4. Filtrar CD_CONTA_CONTABIL == 31\n",
        "                                # Convertemos para string para garantir a comparação exata\n",
        "                                df_filtrado = df[df['CD_CONTA_CONTABIL'] == '31'].copy()\n",
        "\n",
        "                                if not df_filtrado.empty:\n",
        "                                    # 5. Adicionar coluna de Trimestre\n",
        "                                    df_filtrado['ID_TRIMESTRE'] = chave_trimestre\n",
        "\n",
        "                                    # Conversão de tipos úteis (Ex: VL_SALDO_FINAL para float)\n",
        "                                    # A ANS usa vírgula como decimal no CSV pt-br\n",
        "                                    if 'VL_SALDO_FINAL' in df_filtrado.columns:\n",
        "                                        df_filtrado['VL_SALDO_FINAL'] = df_filtrado['VL_SALDO_FINAL'].str.replace(',', '.', regex=False)\n",
        "                                        df_filtrado['VL_SALDO_FINAL'] = pd.to_numeric(df_filtrado['VL_SALDO_FINAL'], errors='coerce')\n",
        "\n",
        "                                    # 6. Salvar no Banco\n",
        "                                    df_filtrado.to_sql(tabela_destino, conn, if_exists='append', index=False)\n",
        "                                    print(f\"      -> Sucesso! {len(df_filtrado)} registros conta 31 salvos.\")\n",
        "                                else:\n",
        "                                    print(\"      -> Arquivo lido, mas sem registros da conta 31.\")\n",
        "                            else:\n",
        "                                print(f\"      -> Coluna CD_CONTA_CONTABIL não encontrada. Colunas: {list(df.columns)}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"      -> Erro ao processar zip: {e}\")\n",
        "\n",
        "        conn.close()\n",
        "        print(\"--- Extração Contábil Finalizada ---\")\n",
        "\n",
        "# --- EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Importante: Use o MESMO nome de banco que você usou no script anterior\n",
        "    # para que as tabelas fiquem juntas.\n",
        "    # Exemplo anterior: 'base_ans_paralela.db' ou 'base_ans_v2.db'\n",
        "\n",
        "    db_nome = 'base_ans_paralela.db'\n",
        "\n",
        "    print(f\"Iniciando extração contábil para o banco: {db_nome}\")\n",
        "    extrator = ExtratorContabil(db_path=db_nome)\n",
        "    extrator.executar_extracao()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_8Kwf4PPP5pw",
        "outputId": "3e1ad221-cd7d-4d3d-886c-8bb6487ec656"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando extração contábil para o banco: base_ans_paralela.db\n",
            "--- Buscando pastas de anos em: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/ ---\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2007/\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2007_1_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2007_2_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2007_3_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2007_4_trimestre.zip\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2008/\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2008_1_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2008_2_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2008_3_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2008_4_trimestre.zip\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2009/\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2009_1_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2009_2_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2009_3_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2009_4_trimestre.zip\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2010/\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2010_1_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2010_2_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2010_3_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 2010_4_trimestre.zip\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2011/\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 20120614_2011_1_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 20120614_2011_2_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 20120614_2011_3_trimestre.zip\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 20120614_2011_4_trimestre.zip\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2012/\n",
            "   Processing: 20130416_1T2012.zip -> Trimestre: 2012-T1\n",
            "      -> Sucesso! 963 registros conta 31 salvos.\n",
            "   Processing: 20130416_2T2012.zip -> Trimestre: 2012-T2\n",
            "      -> Sucesso! 965 registros conta 31 salvos.\n",
            "   Processing: 20130416_3T2012.zip -> Trimestre: 2012-T3\n",
            "      -> Sucesso! 962 registros conta 31 salvos.\n",
            "   Processing: 20130416_4T2012.zip -> Trimestre: 2012-T4\n",
            "      -> Sucesso! 1216 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2013/\n",
            "   Processing: 2013-1t.zip -> Trimestre: 2013-T1\n",
            "      -> Sucesso! 952 registros conta 31 salvos.\n",
            "   Processing: 2013-2t.zip -> Trimestre: 2013-T2\n",
            "      -> Sucesso! 953 registros conta 31 salvos.\n",
            "   Processing: 2013-3t.zip -> Trimestre: 2013-T3\n",
            "      -> Sucesso! 958 registros conta 31 salvos.\n",
            "   Processing: 2013-4t.zip -> Trimestre: 2013-T4\n",
            "      -> Sucesso! 1189 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2014/\n",
            "   Processing: 1T2014.zip -> Trimestre: 2014-T1\n",
            "      -> Sucesso! 944 registros conta 31 salvos.\n",
            "   Processing: 2T2014.zip -> Trimestre: 2014-T2\n",
            "      -> Sucesso! 949 registros conta 31 salvos.\n",
            "   Processing: 3T2014.zip -> Trimestre: 2014-T3\n",
            "      -> Sucesso! 947 registros conta 31 salvos.\n",
            "   Processing: 4T2014.zip -> Trimestre: 2014-T4\n",
            "      -> Sucesso! 1170 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2015/\n",
            "   Processing: 1T2015.zip -> Trimestre: 2015-T1\n",
            "      -> Sucesso! 927 registros conta 31 salvos.\n",
            "   Processing: 2T2015.zip -> Trimestre: 2015-T2\n",
            "      -> Sucesso! 922 registros conta 31 salvos.\n",
            "   Processing: 3T2015.zip -> Trimestre: 2015-T3\n",
            "      -> Sucesso! 916 registros conta 31 salvos.\n",
            "   Processing: 4T2015.zip -> Trimestre: 2015-T4\n",
            "      -> Sucesso! 1142 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2016/\n",
            "   Processing: 1T2016.zip -> Trimestre: 2016-T1\n",
            "      -> Sucesso! 908 registros conta 31 salvos.\n",
            "   Processing: 2T2016.zip -> Trimestre: 2016-T2\n",
            "      -> Sucesso! 904 registros conta 31 salvos.\n",
            "   Processing: 3T2016.zip -> Trimestre: 2016-T3\n",
            "      -> Sucesso! 902 registros conta 31 salvos.\n",
            "   Processing: 4T2016.zip -> Trimestre: 2016-T4\n",
            "      -> Sucesso! 1115 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2017/\n",
            "   Processing: 1T2017.zip -> Trimestre: 2017-T1\n",
            "      -> Sucesso! 901 registros conta 31 salvos.\n",
            "   Processing: 2T2017.zip -> Trimestre: 2017-T2\n",
            "      -> Sucesso! 886 registros conta 31 salvos.\n",
            "   [Pular] Não foi possível identificar trimestre no nome: 3-Trimestre.zip\n",
            "   Processing: 4T2017.zip -> Trimestre: 2017-T4\n",
            "      -> Sucesso! 1092 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2018/\n",
            "   Processing: 1T2018.zip -> Trimestre: 2018-T1\n",
            "      -> Sucesso! 873 registros conta 31 salvos.\n",
            "   Processing: 2T2018.zip -> Trimestre: 2018-T2\n",
            "      -> Sucesso! 876 registros conta 31 salvos.\n",
            "   Processing: 3T2018.zip -> Trimestre: 2018-T3\n",
            "      -> Sucesso! 880 registros conta 31 salvos.\n",
            "   Processing: 4T2018.zip -> Trimestre: 2018-T4\n",
            "      -> Sucesso! 1071 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2019/\n",
            "   Processing: 1T2019.zip -> Trimestre: 2019-T1\n",
            "      -> Sucesso! 854 registros conta 31 salvos.\n",
            "   Processing: 2T2019.zip -> Trimestre: 2019-T2\n",
            "      -> Sucesso! 865 registros conta 31 salvos.\n",
            "   Processing: 3T2019.zip -> Trimestre: 2019-T3\n",
            "      -> Sucesso! 866 registros conta 31 salvos.\n",
            "   Processing: 4T2019.zip -> Trimestre: 2019-T4\n",
            "      -> Sucesso! 1047 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2020/\n",
            "   Processing: 1T2020.zip -> Trimestre: 2020-T1\n",
            "      -> Sucesso! 849 registros conta 31 salvos.\n",
            "   Processing: 2T2020.zip -> Trimestre: 2020-T2\n",
            "      -> Sucesso! 846 registros conta 31 salvos.\n",
            "   Processing: 3T2020.zip -> Trimestre: 2020-T3\n",
            "      -> Sucesso! 839 registros conta 31 salvos.\n",
            "   Processing: 4T2020.zip -> Trimestre: 2020-T4\n",
            "      -> Sucesso! 1027 registros conta 31 salvos.\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2021/\n",
            "   Processing: 1T2021.zip -> Trimestre: 2021-T1\n",
            "      -> Sucesso! 842 registros conta 31 salvos.\n",
            "   Processing: 2T2021.zip -> Trimestre: 2021-T2\n",
            "      -> Sucesso! 858 registros conta 31 salvos.\n",
            "   Processing: 3T2021.zip -> Trimestre: 2021-T3\n",
            "      -> Sucesso! 860 registros conta 31 salvos.\n",
            "   Processing: 4T2021.zip -> Trimestre: 2021-T4\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2022/\n",
            "   Processing: 1T2022.zip -> Trimestre: 2022-T1\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 2T2022.zip -> Trimestre: 2022-T2\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 3T2022.zip -> Trimestre: 2022-T3\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 4T2022.zip -> Trimestre: 2022-T4\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2023/\n",
            "   Processing: 1T2023.zip -> Trimestre: 2023-T1\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 2T2023.zip -> Trimestre: 2023-T2\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 3T2023.zip -> Trimestre: 2023-T3\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 4T2023.zip -> Trimestre: 2023-T4\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2024/\n",
            "   Processing: 1T2024.zip -> Trimestre: 2024-T1\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 2T2024.zip -> Trimestre: 2024-T2\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 3T2024.zip -> Trimestre: 2024-T3\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 4T2024.zip -> Trimestre: 2024-T4\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "> Entrando na pasta: https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/2025/\n",
            "   Processing: 1T2025.zip -> Trimestre: 2025-T1\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 2T2025.zip -> Trimestre: 2025-T2\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "   Processing: 3T2025.zip -> Trimestre: 2025-T3\n",
            "      -> Erro ao processar zip: table demonstracoes_contabeis has no column named VL_SALDO_INICIAL\n",
            "--- Extração Contábil Finalizada ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicio Extração Dimensão Operadora\n"
      ],
      "metadata": {
        "id": "EOFUUIl2d3WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImportadorCadop:\n",
        "    def __init__(self, db_path, csv_path):\n",
        "        self.db_path = db_path\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def _limpar_nome_coluna(self, texto):\n",
        "        \"\"\"Limpa apenas o cabeçalho (nome da coluna) para o banco de dados\"\"\"\n",
        "        txt = unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('ASCII')\n",
        "        return txt.strip().lower().replace(' ', '_').replace('.', '').replace('/', '')\n",
        "\n",
        "    def processar_cadop(self, tabela_destino='dim_operadoras'):\n",
        "        if not os.path.exists(self.csv_path):\n",
        "            print(f\"ERRO: Arquivo não encontrado: {self.csv_path}\")\n",
        "            return\n",
        "\n",
        "        print(f\"--- Atualizando Tabela CADOP (Correção de Acentos) ---\")\n",
        "\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "\n",
        "            # 1. MUDANÇA CRÍTICA: encoding='utf-8-sig'\n",
        "            # 'utf-8' resolve o problema do \"SÃ£o\".\n",
        "            # O sufixo '-sig' é importante caso o arquivo tenha sido salvo pelo Excel (remove caracteres ocultos no início).\n",
        "            # dtype=str: Lemos TUDO como texto para proteger CPNJ e Código ANS (zeros a esquerda).\n",
        "            df = pd.read_csv(\n",
        "                self.csv_path,\n",
        "                sep=';',\n",
        "                encoding='utf-8-sig',\n",
        "                dtype=str\n",
        "            )\n",
        "\n",
        "            # 2. Padronizar nomes das colunas\n",
        "            df.columns = [self._limpar_nome_coluna(c) for c in df.columns]\n",
        "\n",
        "            # 3. TRATAMENTO INTELIGENTE DE COLUNAS\n",
        "            # O usuário pediu para verificar string vs int.\n",
        "            # Como carregamos tudo como 'str' para segurança, iteramos para limpar o texto.\n",
        "\n",
        "            print(\"   Aplicando tratamento nas colunas de texto...\")\n",
        "            for coluna in df.columns:\n",
        "                # Verifica se a coluna é do tipo objeto (string/texto)\n",
        "                if df[coluna].dtype == 'object':\n",
        "                    # .str.strip() remove espaços vazios no começo e fim que atrapalham SQL\n",
        "                    # Ex: \"São Paulo \" vira \"São Paulo\"\n",
        "                    df[coluna] = df[coluna].str.strip()\n",
        "\n",
        "            print(f\"   Colunas processadas: {list(df.columns[:5])} ...\")\n",
        "\n",
        "            # 4. Salvar no SQLite (DROP e CREATE com if_exists='replace')\n",
        "            df.to_sql(tabela_destino, conn, if_exists='replace', index=False)\n",
        "\n",
        "            # 5. Recriar Índice\n",
        "            if 'registro_ans' in df.columns:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(f'CREATE INDEX IF NOT EXISTS idx_cadop_reg ON {tabela_destino}(registro_ans);')\n",
        "                conn.commit()\n",
        "\n",
        "            conn.close()\n",
        "\n",
        "            # Validação visual\n",
        "            exemplo_cidade = df['bairro'].iloc[0] if 'bairro' in df.columns else 'Coluna não achada'\n",
        "            exemplo_razao = df['razao_social'].iloc[0]\n",
        "            print(f\"   -> Sucesso! Tabela atualizada.\")\n",
        "            print(f\"   -> Teste de Acento: '{exemplo_razao}'\")\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            print(\"   -> ERRO DE ENCODING: O arquivo não é UTF-8. Tente trocar para 'latin-1' no código.\")\n",
        "        except Exception as e:\n",
        "            print(f\"   -> Erro ao processar: {e}\")\n",
        "\n",
        "# --- EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    db_nome = 'base_ans_paralela.db'\n",
        "    arquivo_csv = 'Relatorio_cadop.csv'\n",
        "\n",
        "    if os.path.exists(arquivo_csv):\n",
        "        importador = ImportadorCadop(db_path=db_nome, csv_path=arquivo_csv)\n",
        "        importador.processar_cadop()\n",
        "    else:\n",
        "        print(f\"Arquivo {arquivo_csv} não encontrado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0KXwXwhd9nB",
        "outputId": "e1b26d1e-be7c-4408-e982-b406c8802e5f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Atualizando Tabela CADOP (Correção de Acentos) ---\n",
            "   Aplicando tratamento nas colunas de texto...\n",
            "   Colunas processadas: ['registro_operadora', 'cnpj', 'razao_social', 'nome_fantasia', 'modalidade'] ...\n",
            "   -> Sucesso! Tabela atualizada.\n",
            "   -> Teste de Acento: '18 DE JULHO ADMINISTRADORA DE BENEFÍCIOS LTDA'\n"
          ]
        }
      ]
    }
  ]
}